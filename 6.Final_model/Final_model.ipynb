{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c2ca69f",
   "metadata": {},
   "source": [
    "## <font color=\"Blue\">Phishing URL Detection - ConvXGB Model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fbed47",
   "metadata": {},
   "source": [
    "<b>GOAL:</b> This study employs new deep learning algorithm named \"ConvXGB\" to the field of cybersecurity in detecting phishing URL.</br>\n",
    "<b>Author :</b> Saravanan Muthuramalingam </br>\n",
    "<b>Purpose of this notebook :</b> This Notebook handles the following,\n",
    "    <li> Hyperparamter Tuning </li>\n",
    "    <li> EPOCH = 75 </li>\n",
    "    <li> Dropout = 0.5 </li>\n",
    "    <li>SMOTE ENN</li>\n",
    "        <li>STRATIFIED K-FOLD</li>\n",
    "        <li> removed LeakyRelu </li>\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e771f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required python libraries\n",
    "#-------------------------------------#\n",
    "# Statistics Libraries\n",
    "import numpy as np\n",
    "\n",
    "# Dataset related Libraires\n",
    "import pandas as pd \n",
    "import csv\n",
    "\n",
    "# Data Visualization Libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# URL Parsing Libraries\n",
    "import urllib.parse\n",
    "from urllib.parse import urlparse\n",
    "from urllib.parse import urlsplit\n",
    "from urlpath import URL\n",
    "\n",
    "# OS and regular expression Libraries\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Image processing related Libraries\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import skimage.measure\n",
    "import imghdr\n",
    "\n",
    "# Image validation related Libraries\n",
    "from difPy import dif\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# To Build CNN in Keras \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, Adadelta, RMSprop\n",
    "\n",
    "# XGBoost classification algorithm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Perforrmance evaluation Librraries\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c22c8",
   "metadata": {},
   "source": [
    "#### <font color='blue'>7. Splitting Train/Test Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667dcd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting test and train\n",
    "#80% of the datasets is reserved for training the model\n",
    "raw_df = pd.read_csv(r'C:\\Users\\msara\\Desktop\\dataset\\preprocessed_data.csv')\n",
    "#raw_df = raw_df.drop(columns=['protocol'])\n",
    "raw_df['split'] = np.random.randn(raw_df.shape[0], 1)\n",
    "\n",
    "#msk = np.random.rand(len(raw_df)) <= 0.8\n",
    "\n",
    "#train = raw_df[msk]\n",
    "#test = raw_df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb37186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = raw_df.pop('result')\n",
    "\n",
    "X = raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c8a65f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Phishing vs Legitmate count')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#before class imablance\n",
    "y.value_counts().plot.bar()\n",
    "plt.title(\"Phishing vs Legitmate count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38727bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13948\n",
       "1     3735\n",
       "Name: result, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e80fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0: 78.24868183941801 %\n",
      "class 1: 21.75131816058199\n"
     ]
    }
   ],
   "source": [
    "print(\"class 0:\",11724 *100/(11724+3259),\"%\")\n",
    "print(\"class 1:\",3259* 100/(11724+3259))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75564749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17683, 786)\n",
      "(17683,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543d279e",
   "metadata": {},
   "source": [
    "#### Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f45d900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classs imabalance\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#from imblearn.over_sampling import ADASYN\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "sm = SMOTEENN(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20035483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18417, 786)\n",
      "(18417,)\n"
     ]
    }
   ],
   "source": [
    "#Oversampling results\n",
    "print(X_res.shape)\n",
    "print(y_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a62d2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([X_res,y_res],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2694edc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "      <th>pixel785</th>\n",
       "      <th>split</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>253.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>...</td>\n",
       "      <td>246.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.138385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.838566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.794656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>108.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.625356</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.775980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 787 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0           6   253.0   253.0   253.0   253.0   253.0   230.0   231.0   232.0   \n",
       "1          23    38.0    38.0    38.0    38.0    37.0    43.0    49.0    44.0   \n",
       "2          44    39.0    39.0    39.0    39.0    40.0    38.0    59.0    55.0   \n",
       "3          59   108.0    71.0    75.0    66.0    71.0    94.0    84.0    83.0   \n",
       "4          90    10.0     6.0     3.0     2.0     0.0     4.0     2.0     0.0   \n",
       "\n",
       "   pixel10  ...  pixel778  pixel779  pixel780  pixel781  pixel782  pixel783  \\\n",
       "0    236.0  ...     246.0     242.0     248.0     252.0     252.0     252.0   \n",
       "1     44.0  ...      30.0      30.0      30.0      30.0      30.0      28.0   \n",
       "2     37.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3    107.0  ...      51.0      49.0      50.0      50.0      50.0      50.0   \n",
       "4      4.0  ...      10.0      10.0      10.0      10.0      10.0      10.0   \n",
       "\n",
       "   pixel784  pixel785     split  result  \n",
       "0     252.0     252.0  0.138385       0  \n",
       "1      46.0      40.0  0.838566       0  \n",
       "2       0.0       0.0 -1.794656       0  \n",
       "3      50.0      50.0  1.625356       0  \n",
       "4      10.0      10.0 -0.775980       0  \n",
       "\n",
       "[5 rows x 787 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ee620d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#after class imablance\n",
    "y_res.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e365a1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18417, 785)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = new_df.copy()\n",
    "raw_df = raw_df.drop(['Unnamed: 0', 'split'],axis=1)\n",
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0623c254",
   "metadata": {},
   "source": [
    "#### <font color='blue'>9. Train/Test Data Pre-processing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30e35d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unwanted columns from train dataset\n",
    "#train = train.drop(['Unnamed: 0', 'protocol','split'],axis=1)\n",
    "#print(\"Train_data shape:\", train.shape)\n",
    "\n",
    "# Removing unwanted columns from test dataset\n",
    "#test = test.drop(['Unnamed: 0', 'protocol', 'split'],axis=1)\n",
    "#print(\"Test_data shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad47a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(raw_df)) <= 0.7\n",
    "\n",
    "train = raw_df[msk]\n",
    "test = raw_df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5790b130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12903, 785)\n",
      "(5514, 785)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c3ef086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (12903, 785)\n",
      "val shape: (5114, 785)\n",
      "train_label shape: (12903,)\n",
      "val_label shape: (5114,)\n",
      "train_image shape: (12903, 784)\n",
      "val_image shape: (5114, 784)\n",
      "test_image shape: (5514, 784)\n",
      "test_label shape: (5514,)\n"
     ]
    }
   ],
   "source": [
    "#converting the data to appropripate shapes using numpy\n",
    "train_data = train[:]\n",
    "val_data = test[400:]\n",
    "train_label = np.float32(train_data.result)\n",
    "val_label = np.float32(val_data.result)\n",
    "train_image = np.float32(train_data[train_data.columns[1:]])\n",
    "val_image = np.float32(val_data[val_data.columns[1:]])\n",
    "test_image = np.float32(test[test.columns[1:]])\n",
    "test_label = np.float32(test.result)\n",
    "print('train shape: %s'%str(train_data.shape))\n",
    "print('val shape: %s'%str(val_data.shape))\n",
    "print('train_label shape: %s'%str(train_label.shape))\n",
    "print('val_label shape: %s'%str(val_label.shape))\n",
    "print('train_image shape: %s'%str(train_image.shape))\n",
    "print('val_image shape: %s'%str(val_image.shape))\n",
    "print('test_image shape: %s'%str(test_image.shape))\n",
    "print('test_label shape: %s'%str(test_label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29b95873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12903, 784)\n",
      "(12903, 784)\n",
      "train_image shape: (12903, 28, 28, 1)\n",
      "train_image shape: (12903, 28, 28, 1)\n",
      "val_image shape: (5114, 28, 28, 1)\n",
      "(5114,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.show()\n",
    "print(train_image.shape)\n",
    "\n",
    "train_image = train_image/255.0\n",
    "val_image = val_image/255.0\n",
    "test_image = test_image/255.0\n",
    "\n",
    "print(train_image.shape)\n",
    "\n",
    "#28 x 28 = 784\n",
    "train_image = train_image.reshape(train_image.shape[0],28,28,1)\n",
    "val_image = val_image.reshape(val_image.shape[0],28,28,1)\n",
    "test_image = test_image.reshape(test_image.shape[0],28,28,1)\n",
    "\n",
    "\n",
    "print('train_image shape: %s'%str(train_image.shape))\n",
    "\n",
    "print('train_image shape: %s'%str(train_image.shape))\n",
    "print('val_image shape: %s'%str(val_image.shape))\n",
    "\n",
    "train_label1 = train_label\n",
    "val_label1 = val_label\n",
    "print(val_label1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2f8802",
   "metadata": {},
   "source": [
    "#### <font color='blue'>10. One Hot Encoding</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e8c379b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_label shape: (12903, 10)\n",
      "val_label shape: (5114, 10)\n"
     ]
    }
   ],
   "source": [
    "#onehot encoding\n",
    "encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "yy = [[0],[1],[2],[3],[4],[5],[6],[7],[8],[9]]\n",
    "encoder.fit(yy)\n",
    "# transform\n",
    "train_label = train_label.reshape(-1,1)\n",
    "val_label = val_label.reshape(-1,1)\n",
    "\n",
    "train_label = encoder.transform(train_label)\n",
    "val_label = encoder.transform(val_label)\n",
    "\n",
    "print('train_label shape: %s'%str(train_label.shape))\n",
    "print('val_label shape: %s'%str(val_label.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4877b91",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### <font color='blue'> 11. CNN Model Building </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9751ccc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 128)         204928    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 128)         409728    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 3, 3, 128)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 3, 3, 256)         819456    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 3, 3, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 3, 3, 256)         1638656   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 3, 3, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " my_dense (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,241,578\n",
      "Trainable params: 3,239,658\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN Model Building\n",
    "\n",
    "# input: 28x28 images with 1 channels -> (28, 28, 1) tensors.\n",
    "#REason for having grey scale 1 channel\n",
    "# https://stackoverflow.com/questions/53044116/difference-between-grayscale-images-represented-by-3-channels-and-1-channel-in-c#:~:text=The%20information%20given%20by%20the,take%20more%20time%20to%20compute\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "# First two convolution layer has 32 Feature Maps\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1),padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Subsequent two convolution layer has 64 Feature Maps\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Next two convolution layer has 128 Feature Maps\n",
    "model.add(Conv2D(128, kernel_size=5, activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(128, kernel_size=5, activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Final two convolution layer has 128 Feature Maps\n",
    "model.add(Conv2D(256, kernel_size=5, activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(256, kernel_size=5, activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "# Dense Layer\n",
    "#model = keras.applications.inception_v3.InceptionV3(weights= None, include_top=False, input_shape= (28,28,1))\n",
    "model.add(Dense(256, activation='relu', name='my_dense'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b3e2df",
   "metadata": {},
   "source": [
    "#### <font color='blue'> 11. Creating Intermediate Layer </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b60cd20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 128)         204928    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 128)         409728    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 3, 3, 128)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 3, 3, 256)         819456    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 3, 3, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 3, 3, 256)         1638656   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 3, 3, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " my_dense (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,207,392\n",
      "Trainable params: 3,205,472\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Crating a Intermediate Layer from the CNN's dense layer\n",
    "layer_name='my_dense'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "intermediate_layer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db1da83",
   "metadata": {},
   "source": [
    "#### <font color='blue'> 12. Data Augmentation </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b27c8a",
   "metadata": {},
   "source": [
    "The ImageDataGenerator class in Keras is used for implementing image augmentation. The major advantage of the Keras ImageDataGenerator class is its ability to produce real-time image augmentation. This simply means it can generate augmented images dynamically during the training of the model making the overall mode more robust and accurate."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc5be936",
   "metadata": {},
   "source": [
    "# Data Augmentation using keras\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range = 15,\n",
    "    horizontal_flip = False,\n",
    "    zoom_range = 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d489c108",
   "metadata": {},
   "source": [
    "#### <font color='blue'> 13. Optimisation </font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9beb6633",
   "metadata": {},
   "source": [
    "#0ptimisation - Need to understand how the validation accuracy is compared here for feature extraction\n",
    "#from keras.optimizers import Adam, Adadelta, RMSprop\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "intermediate_layer_model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "datagen.fit(train_image)\n",
    "\n",
    "# training\n",
    "history = intermediate_layer_model.fit_generator(datagen.flow(train_image,train_label1),\n",
    "                              epochs = 2, #epoch,batch_size can try with different values 50,100,\n",
    "                              shuffle=True,\n",
    "                              validation_data = (val_image,val_label),\n",
    "                              verbose = 1,\n",
    "                              steps_per_epoch=train_image.shape[0] // 32) #ned to change as per above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8f08fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "399/403 [============================>.] - ETA: 0s - loss: 0.5268 - accuracy: 0.7575"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#model.fit(train_image, train_label)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                              \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_label\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3.0\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#model.fit(train_image, train_label)\n",
    "\n",
    "history = model.fit(train_image, train_label,batch_size=32, \n",
    "                              steps_per_epoch=train_image.shape[0] // 32, \n",
    "                              max_queue_size=500,\n",
    "                              workers=1,\n",
    "                              validation_data = (val_image,val_label),\n",
    "                              epochs=75, \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Extract the train - intermediate output from CNN\n",
    "intermediate_output = intermediate_layer_model.predict(train_image) \n",
    "intermediate_output = pd.DataFrame(data=intermediate_output)\n",
    "intermediate_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bde5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of test dataset\n",
    "print(val_image.shape)\n",
    "print(val_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the dataset for XGBoost model building\n",
    "val_data = intermediate_output[7709:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd70a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the test - intermediate output from CNN\n",
    "intermediate_test_output = intermediate_layer_model.predict(test_image)\n",
    "intermediate_test_output = pd.DataFrame(data=intermediate_test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b37b85",
   "metadata": {},
   "source": [
    "#### <font color='blue'> 14. XGBooost model creation for intermediate values </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849eefbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#printing shape of intermediate values\n",
    "print(intermediate_output.shape)\n",
    "print(train_label1.shape)\n",
    "print(val_data.shape)\n",
    "print(val_label1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ccfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "12863 - 5154\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8358af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #XGBoost model creation & XGBoost evaluate predictions\n",
    "\n",
    "xgb_model = XGBClassifier(seed=0)\n",
    "xgb_model.fit(intermediate_output, train_label1)\n",
    "# make predictions for test data\n",
    "y_pred = xgb_model.predict(val_data)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(val_label1, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "#xgb_model.score(val_data, val_label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f4638f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab942369",
   "metadata": {},
   "source": [
    "Accuracy of XGBoost seems to be less, this could be due to less validation set, hence lets intorduce K-Fold cross validation to mitigate this issue and increase the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dc82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_xgb = xgb_model.predict(intermediate_test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66adb715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = list()\n",
    "resample_xgb = list()\n",
    "precision_xgb = list()\n",
    "recall_xgb = list()\n",
    "F1score_xgb = list()\n",
    "AUCROC_xgb = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval( y_test, y_pred, algo=None, sampling=None):\n",
    "    # Test set prediction\n",
    "    #y_prob=clf_model.predict_proba(X_test)\n",
    "    #y_pred=clf_model.predict(X_test)\n",
    "    \n",
    "    #print('Confusion Matrix')\n",
    "    print('='*60)\n",
    "    print('Classification Report')\n",
    "    print('='*60)\n",
    "    print(classification_report(y_test,y_pred),\"\\n\")\n",
    "    #print('AUC-ROC')\n",
    "    #print('='*60)\n",
    "    #print(roc_auc_score(y_test, y_prob[:,1]))\n",
    "          \n",
    "    #model.append(algo)\n",
    "    precision_xgb.append(precision_score(y_test, y_pred))\n",
    "    recall_xgb.append(recall_score(y_test, y_pred))\n",
    "    F1score_xgb.append(f1_score(y_test, y_pred))\n",
    "    #AUCROC.append(roc_auc_score(y_test, y_prob[:,1]))\n",
    "    #resample.append(sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dec3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval(test_label, submission_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca93c3",
   "metadata": {},
   "source": [
    "https://github.com/arpcode/SMOTE-ADA-BOOST-COBRA/blob/main/Notebooks/SmoteAdaBoostedCC.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc418531",
   "metadata": {},
   "source": [
    "#### <font color='blue'>  K-Fold Validation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec15c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ceef3d",
   "metadata": {},
   "source": [
    "#### Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de409efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Accuracy\n",
    "# k-fold cross validation evaluation of xgboost model\n",
    "from numpy import loadtxt\n",
    "import xgboost\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "#kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "kfold = StratifiedKFold(n_splits=15, random_state=7, shuffle=True)\n",
    "results = cross_val_score(xgb_model, intermediate_output, train_label1, cv=kfold)\n",
    "#Test_results = cross_val_score(xgb_model, intermediate_output, val_label1, cv=kfold)\n",
    "#cv_results = cross_validate(xgb_model, X, y, cv=kfold, scoring=accuracy, verbose=10)\n",
    "print(\"Accuracy: %.2f%%\" % (results.mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89a0d8b",
   "metadata": {},
   "source": [
    "#### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a8e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Accuracy\n",
    "kfold = StratifiedKFold(n_splits=15, random_state=7, shuffle=True)\n",
    "test_results = cross_val_score(xgb_model, intermediate_test_output, test_label, cv=kfold)\n",
    "#Test_results = cross_val_score(xgb_model, intermediate_output, val_label1, cv=kfold)\n",
    "#cv_results = cross_validate(xgb_model, X, y, cv=kfold, scoring=accuracy, verbose=10)\n",
    "print(\"Accuracy: %.2f%%\" % (test_results.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a638c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_label1.shape)\n",
    "print(test_label.shape)\n",
    "print(val_label1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06d0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters of XGB model\n",
    "xgb_model.get_xgb_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ab928b",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Ploting confusion matrix </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c78d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(test_label, submission_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70043ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TYPE-1 Error = False Positive = 4.66%  # predicted value is postive but it is false\n",
    "# TYPE-2 Error - False Negative = 10.39%  # predicted value is negative but it is true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                confusion_matrix(test_label, submission_xgb).flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     confusion_matrix(test_label, submission_xgb).flatten()/np.sum(confusion_matrix(test_label, submission_xgb))]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(confusion_matrix(test_label, submission_xgb),fmt='', cmap='Blues', annot=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0490a789",
   "metadata": {},
   "source": [
    "#### Plotting AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16df4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "from sklearn .metrics import roc_auc_score\n",
    " \n",
    "auc = np.round(roc_auc_score(test_label, submission_xgb), 3)\n",
    " \n",
    "print(\"Auc for model is {}\". format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8deb487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918693dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(test_label, submission_xgb)\n",
    "plt.title(\"AUC-ROC Curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e2ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
