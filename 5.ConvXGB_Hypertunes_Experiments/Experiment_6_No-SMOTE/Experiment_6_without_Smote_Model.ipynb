{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c2ca69f",
   "metadata": {},
   "source": [
    "## <font color=\"Blue\">Phishing URL Detection - ConvXGB Model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fbed47",
   "metadata": {},
   "source": [
    "<b>GOAL:</b> This study employs new deep learning algorithm named \"ConvXGB\" to the field of cybersecurity in detecting phishing URL.</br>\n",
    "<b>Author :</b> Saravanan Muthuramalingam </br>\n",
    "<b>Purpose of this notebook :</b> This Notebook handles the following,\n",
    "    <li> Hyperparamter Tuning </li>\n",
    "    <li> EPOCH = 75 </li>\n",
    "    <li> Dropout = 0.5 </li>\n",
    "        <li> NO SMOTE but has Augmentation </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7a2961",
   "metadata": {},
   "source": [
    "#### <NO SMOTE, but with Augmentation>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e771f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required python libraries\n",
    "#-------------------------------------#\n",
    "# Statistics Libraries\n",
    "import numpy as np\n",
    "\n",
    "# Dataset related Libraires\n",
    "import pandas as pd \n",
    "import csv\n",
    "\n",
    "# Data Visualization Libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# URL Parsing Libraries\n",
    "import urllib.parse\n",
    "from urllib.parse import urlparse\n",
    "from urllib.parse import urlsplit\n",
    "from urlpath import URL\n",
    "\n",
    "# OS and regular expression Libraries\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Image processing related Libraries\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import skimage.measure\n",
    "import imghdr\n",
    "\n",
    "# Image validation related Libraries\n",
    "from difPy import dif\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# To Build CNN in Keras \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, Adadelta, RMSprop\n",
    "\n",
    "# XGBoost classification algorithm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Perforrmance evaluation Librraries\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c22c8",
   "metadata": {},
   "source": [
    "#### <font color='blue'>7. Splitting Train/Test Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "667dcd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17683, 785)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spliting test and train\n",
    "#80% of the datasets is reserved for training the model\n",
    "raw_df = pd.read_csv(r'C:\\Users\\msara\\Desktop\\dataset\\preprocessed_data.csv')\n",
    "raw_df['split'] = np.random.randn(raw_df.shape[0], 1)\n",
    "\n",
    "\n",
    "\n",
    "raw_df = raw_df.drop(['Unnamed: 0', 'split'],axis=1)\n",
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0623c254",
   "metadata": {},
   "source": [
    "#### <font color='blue'>9. Train/Test Data Pre-processing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70963acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(raw_df)) <= 0.8\n",
    "\n",
    "train = raw_df[msk]\n",
    "test = raw_df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c3ef086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (14123, 785)\n",
      "val shape: (3160, 785)\n",
      "train_label shape: (14123,)\n",
      "val_label shape: (3160,)\n",
      "train_image shape: (14123, 784)\n",
      "val_image shape: (3160, 784)\n",
      "test_image shape: (3560, 784)\n",
      "test_label shape: (3560,)\n"
     ]
    }
   ],
   "source": [
    "#converting the data to appropripate shapes using numpy\n",
    "train_data = train[:]\n",
    "val_data = test[400:]\n",
    "train_label = np.float32(train_data.result)\n",
    "val_label = np.float32(val_data.result)\n",
    "train_image = np.float32(train_data[train_data.columns[1:]])\n",
    "val_image = np.float32(val_data[val_data.columns[1:]])\n",
    "test_image = np.float32(test[test.columns[1:]])\n",
    "test_label = np.float32(test.result)\n",
    "print('train shape: %s'%str(train_data.shape))\n",
    "print('val shape: %s'%str(val_data.shape))\n",
    "print('train_label shape: %s'%str(train_label.shape))\n",
    "print('val_label shape: %s'%str(val_label.shape))\n",
    "print('train_image shape: %s'%str(train_image.shape))\n",
    "print('val_image shape: %s'%str(val_image.shape))\n",
    "print('test_image shape: %s'%str(test_image.shape))\n",
    "print('test_label shape: %s'%str(test_label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29b95873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14123, 784)\n",
      "(14123, 784)\n",
      "train_image shape: (14123, 28, 28, 1)\n",
      "train_image shape: (14123, 28, 28, 1)\n",
      "val_image shape: (3160, 28, 28, 1)\n",
      "(3160,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.show()\n",
    "print(train_image.shape)\n",
    "\n",
    "train_image = train_image/255.0\n",
    "val_image = val_image/255.0\n",
    "test_image = test_image/255.0\n",
    "\n",
    "print(train_image.shape)\n",
    "\n",
    "train_image = train_image.reshape(train_image.shape[0],28,28,1)\n",
    "val_image = val_image.reshape(val_image.shape[0],28,28,1)\n",
    "test_image = test_image.reshape(test_image.shape[0],28,28,1)\n",
    "print('train_image shape: %s'%str(train_image.shape))\n",
    "\n",
    "print('train_image shape: %s'%str(train_image.shape))\n",
    "print('val_image shape: %s'%str(val_image.shape))\n",
    "\n",
    "train_label1 = train_label\n",
    "val_label1 = val_label\n",
    "print(val_label1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2f8802",
   "metadata": {},
   "source": [
    "#### <font color='blue'>10. One Hot Encoding</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e8c379b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_label shape: (14123, 10)\n",
      "val_label shape: (3160, 10)\n"
     ]
    }
   ],
   "source": [
    "#onehot encoding\n",
    "encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "yy = [[0],[1],[2],[3],[4],[5],[6],[7],[8],[9]]\n",
    "encoder.fit(yy)\n",
    "# transform\n",
    "train_label = train_label.reshape(-1,1)\n",
    "val_label = val_label.reshape(-1,1)\n",
    "\n",
    "train_label = encoder.transform(train_label)\n",
    "val_label = encoder.transform(val_label)\n",
    "\n",
    "print('train_label shape: %s'%str(train_label.shape))\n",
    "print('val_label shape: %s'%str(val_label.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4877b91",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### <font color='blue'> 11. CNN Model Building </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9751ccc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 128)         204928    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 128)         409728    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 3, 3, 128)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 3, 3, 256)         819456    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 3, 3, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 3, 3, 256)         1638656   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 3, 3, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " my_dense (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,241,578\n",
      "Trainable params: 3,239,658\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN Model Building\n",
    "model = Sequential()\n",
    "# input: 28x28 images with 1 channels -> (28, 28, 1) tensors.\n",
    "#REason for having grey scale 1 channel\n",
    "# https://stackoverflow.com/questions/53044116/difference-between-grayscale-images-represented-by-3-channels-and-1-channel-in-c#:~:text=The%20information%20given%20by%20the,take%20more%20time%20to%20compute\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "# First two convolution layer has 32 Feature Maps\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1),padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "# Subsequent two convolution layer has 64 Feature Maps\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "# Next two convolution layer has 128 Feature Maps\n",
    "model.add(Conv2D(128, kernel_size=5, activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(128, kernel_size=5, activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "# Final two convolution layer has 128 Feature Maps\n",
    "model.add(Conv2D(256, kernel_size=5, activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(256, kernel_size=5, activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "# Dense Layer\n",
    "#model = keras.applications.inception_v3.InceptionV3(weights= None, include_top=False, input_shape= (28,28,1))\n",
    "model.add(Dense(256, activation='relu', name='my_dense'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b3e2df",
   "metadata": {},
   "source": [
    "#### <font color='blue'> 11. Creating Intermediate Layer </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b60cd20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 128)         204928    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 128)         409728    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 3, 3, 128)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 3, 3, 256)         819456    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 3, 3, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 3, 3, 256)         1638656   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 3, 3, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " my_dense (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,207,392\n",
      "Trainable params: 3,205,472\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Crating a Intermediate Layer from the CNN's dense layer\n",
    "layer_name='my_dense'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "intermediate_layer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db1da83",
   "metadata": {},
   "source": [
    "#### <font color='blue'> 12. Data Augmentation </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b27c8a",
   "metadata": {},
   "source": [
    "The ImageDataGenerator class in Keras is used for implementing image augmentation. The major advantage of the Keras ImageDataGenerator class is its ability to produce real-time image augmentation. This simply means it can generate augmented images dynamically during the training of the model making the overall mode more robust and accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86be8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation using keras\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range = 15,\n",
    "    horizontal_flip = False,\n",
    "    zoom_range = 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d489c108",
   "metadata": {},
   "source": [
    "#### <font color='blue'> 13. Optimisation </font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9beb6633",
   "metadata": {},
   "source": [
    "#0ptimisation - Need to understand how the validation accuracy is compared here for feature extraction\n",
    "#from keras.optimizers import Adam, Adadelta, RMSprop\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "intermediate_layer_model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "datagen.fit(train_image)\n",
    "\n",
    "# training\n",
    "history = intermediate_layer_model.fit_generator(datagen.flow(train_image,train_label, batch_size=32),\n",
    "                              epochs = 2, #epoch,batch_size can try with different values 50,100,\n",
    "                              shuffle=True,\n",
    "                              validation_data = (val_image,val_label),\n",
    "                              verbose = 1,\n",
    "                              steps_per_epoch=train_image.shape[0] // 32) #ned to change as per above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05d5c258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "441/441 [==============================] - 73s 162ms/step - loss: 0.5328 - accuracy: 0.7871 - val_loss: 0.4176 - val_accuracy: 0.8158\n",
      "Epoch 2/75\n",
      "441/441 [==============================] - 68s 153ms/step - loss: 0.4653 - accuracy: 0.7922 - val_loss: 0.4662 - val_accuracy: 0.8089\n",
      "Epoch 3/75\n",
      "441/441 [==============================] - 67s 152ms/step - loss: 0.4549 - accuracy: 0.8021 - val_loss: 0.4252 - val_accuracy: 0.8089\n",
      "Epoch 4/75\n",
      "441/441 [==============================] - 69s 158ms/step - loss: 0.4518 - accuracy: 0.7987 - val_loss: 0.5217 - val_accuracy: 0.8089\n",
      "Epoch 5/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4492 - accuracy: 0.8026 - val_loss: 0.4054 - val_accuracy: 0.8089\n",
      "Epoch 6/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4431 - accuracy: 0.8020 - val_loss: 0.4320 - val_accuracy: 0.8089\n",
      "Epoch 7/75\n",
      "441/441 [==============================] - 67s 151ms/step - loss: 0.4452 - accuracy: 0.8017 - val_loss: 0.3846 - val_accuracy: 0.8335\n",
      "Epoch 8/75\n",
      "441/441 [==============================] - 65s 148ms/step - loss: 0.4397 - accuracy: 0.8039 - val_loss: 1.5788 - val_accuracy: 0.4927\n",
      "Epoch 9/75\n",
      "441/441 [==============================] - 65s 148ms/step - loss: 0.4358 - accuracy: 0.8059 - val_loss: 0.3807 - val_accuracy: 0.8459\n",
      "Epoch 10/75\n",
      "441/441 [==============================] - 65s 148ms/step - loss: 0.4359 - accuracy: 0.8080 - val_loss: 0.3822 - val_accuracy: 0.8206\n",
      "Epoch 11/75\n",
      "441/441 [==============================] - 66s 149ms/step - loss: 0.4339 - accuracy: 0.8087 - val_loss: 0.3842 - val_accuracy: 0.8253\n",
      "Epoch 12/75\n",
      "441/441 [==============================] - 66s 149ms/step - loss: 0.4305 - accuracy: 0.8088 - val_loss: 0.9605 - val_accuracy: 0.5769\n",
      "Epoch 13/75\n",
      "441/441 [==============================] - 67s 152ms/step - loss: 0.4384 - accuracy: 0.8070 - val_loss: 0.5046 - val_accuracy: 0.8089\n",
      "Epoch 14/75\n",
      "441/441 [==============================] - 66s 151ms/step - loss: 0.4461 - accuracy: 0.8021 - val_loss: 0.3780 - val_accuracy: 0.8500\n",
      "Epoch 15/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4385 - accuracy: 0.8060 - val_loss: 0.5524 - val_accuracy: 0.6911\n",
      "Epoch 16/75\n",
      "441/441 [==============================] - 67s 152ms/step - loss: 0.4365 - accuracy: 0.8055 - val_loss: 0.3836 - val_accuracy: 0.8127\n",
      "Epoch 17/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4326 - accuracy: 0.8089 - val_loss: 0.4104 - val_accuracy: 0.8041\n",
      "Epoch 18/75\n",
      "441/441 [==============================] - 66s 151ms/step - loss: 0.4328 - accuracy: 0.8085 - val_loss: 0.5268 - val_accuracy: 0.8016\n",
      "Epoch 19/75\n",
      "441/441 [==============================] - 67s 151ms/step - loss: 0.4302 - accuracy: 0.8119 - val_loss: 0.4020 - val_accuracy: 0.8494\n",
      "Epoch 20/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4258 - accuracy: 0.8104 - val_loss: 1.3653 - val_accuracy: 0.8491\n",
      "Epoch 21/75\n",
      "441/441 [==============================] - 67s 151ms/step - loss: 0.4271 - accuracy: 0.8075 - val_loss: 0.7734 - val_accuracy: 0.8443\n",
      "Epoch 22/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4258 - accuracy: 0.8101 - val_loss: 0.4123 - val_accuracy: 0.8127\n",
      "Epoch 23/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4257 - accuracy: 0.8126 - val_loss: 0.3528 - val_accuracy: 0.8468\n",
      "Epoch 24/75\n",
      "441/441 [==============================] - 67s 151ms/step - loss: 0.4267 - accuracy: 0.8115 - val_loss: 0.4010 - val_accuracy: 0.8101\n",
      "Epoch 25/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4239 - accuracy: 0.8120 - val_loss: 0.3634 - val_accuracy: 0.8222\n",
      "Epoch 26/75\n",
      "441/441 [==============================] - 67s 151ms/step - loss: 0.4197 - accuracy: 0.8163 - val_loss: 0.3619 - val_accuracy: 0.8408\n",
      "Epoch 27/75\n",
      "441/441 [==============================] - 66s 151ms/step - loss: 0.4190 - accuracy: 0.8114 - val_loss: 0.3556 - val_accuracy: 0.8491\n",
      "Epoch 28/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4191 - accuracy: 0.8120 - val_loss: 0.3464 - val_accuracy: 0.8570\n",
      "Epoch 29/75\n",
      "441/441 [==============================] - 66s 151ms/step - loss: 0.4197 - accuracy: 0.8141 - val_loss: 0.3440 - val_accuracy: 0.8532\n",
      "Epoch 30/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4245 - accuracy: 0.8120 - val_loss: 0.3505 - val_accuracy: 0.8592\n",
      "Epoch 31/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4237 - accuracy: 0.8104 - val_loss: 0.3612 - val_accuracy: 0.8566\n",
      "Epoch 32/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4196 - accuracy: 0.8148 - val_loss: 0.4127 - val_accuracy: 0.7968\n",
      "Epoch 33/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4207 - accuracy: 0.8160 - val_loss: 0.3861 - val_accuracy: 0.8307\n",
      "Epoch 34/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4207 - accuracy: 0.8149 - val_loss: 0.3604 - val_accuracy: 0.8468\n",
      "Epoch 35/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4187 - accuracy: 0.8134 - val_loss: 0.3396 - val_accuracy: 0.8570\n",
      "Epoch 36/75\n",
      "441/441 [==============================] - 65s 148ms/step - loss: 0.4163 - accuracy: 0.8153 - val_loss: 0.3442 - val_accuracy: 0.8560\n",
      "Epoch 37/75\n",
      "441/441 [==============================] - 66s 151ms/step - loss: 0.4172 - accuracy: 0.8158 - val_loss: 0.3704 - val_accuracy: 0.8152\n",
      "Epoch 38/75\n",
      "441/441 [==============================] - 67s 151ms/step - loss: 0.4165 - accuracy: 0.8153 - val_loss: 0.3342 - val_accuracy: 0.8535\n",
      "Epoch 39/75\n",
      "441/441 [==============================] - 67s 151ms/step - loss: 0.4165 - accuracy: 0.8136 - val_loss: 0.3442 - val_accuracy: 0.8525\n",
      "Epoch 40/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4149 - accuracy: 0.8157 - val_loss: 0.3392 - val_accuracy: 0.8611\n",
      "Epoch 41/75\n",
      "441/441 [==============================] - 66s 151ms/step - loss: 0.4126 - accuracy: 0.8174 - val_loss: 0.3419 - val_accuracy: 0.8304\n",
      "Epoch 42/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4101 - accuracy: 0.8217 - val_loss: 0.3408 - val_accuracy: 0.8614\n",
      "Epoch 43/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4120 - accuracy: 0.8170 - val_loss: 0.3701 - val_accuracy: 0.8199\n",
      "Epoch 44/75\n",
      "441/441 [==============================] - 67s 151ms/step - loss: 0.4093 - accuracy: 0.8170 - val_loss: 0.3304 - val_accuracy: 0.8563\n",
      "Epoch 45/75\n",
      "441/441 [==============================] - 67s 152ms/step - loss: 0.4145 - accuracy: 0.8153 - val_loss: 0.3642 - val_accuracy: 0.8285\n",
      "Epoch 46/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4107 - accuracy: 0.8165 - val_loss: 0.3320 - val_accuracy: 0.8528\n",
      "Epoch 47/75\n",
      "441/441 [==============================] - 66s 151ms/step - loss: 0.4090 - accuracy: 0.8209 - val_loss: 0.3501 - val_accuracy: 0.8222\n",
      "Epoch 48/75\n",
      "441/441 [==============================] - 67s 152ms/step - loss: 0.4093 - accuracy: 0.8202 - val_loss: 0.3333 - val_accuracy: 0.8535\n",
      "Epoch 49/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4117 - accuracy: 0.8197 - val_loss: 0.3434 - val_accuracy: 0.8503\n",
      "Epoch 50/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4127 - accuracy: 0.8173 - val_loss: 0.3722 - val_accuracy: 0.8253\n",
      "Epoch 51/75\n",
      "441/441 [==============================] - 67s 151ms/step - loss: 0.4085 - accuracy: 0.8239 - val_loss: 0.3259 - val_accuracy: 0.8598\n",
      "Epoch 52/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4086 - accuracy: 0.8216 - val_loss: 0.3535 - val_accuracy: 0.8522\n",
      "Epoch 53/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4080 - accuracy: 0.8214 - val_loss: 0.3456 - val_accuracy: 0.8316\n",
      "Epoch 54/75\n",
      "441/441 [==============================] - 67s 151ms/step - loss: 0.4057 - accuracy: 0.8256 - val_loss: 0.6252 - val_accuracy: 0.7696\n",
      "Epoch 55/75\n",
      "441/441 [==============================] - 66s 151ms/step - loss: 0.4070 - accuracy: 0.8169 - val_loss: 0.3355 - val_accuracy: 0.8601\n",
      "Epoch 56/75\n",
      "441/441 [==============================] - 67s 152ms/step - loss: 0.4060 - accuracy: 0.8219 - val_loss: 0.3373 - val_accuracy: 0.8617\n",
      "Epoch 57/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441/441 [==============================] - 67s 151ms/step - loss: 0.4074 - accuracy: 0.8239 - val_loss: 0.3762 - val_accuracy: 0.8168\n",
      "Epoch 58/75\n",
      "441/441 [==============================] - 66s 151ms/step - loss: 0.4072 - accuracy: 0.8206 - val_loss: 0.3242 - val_accuracy: 0.8611\n",
      "Epoch 59/75\n",
      "441/441 [==============================] - 67s 151ms/step - loss: 0.4019 - accuracy: 0.8239 - val_loss: 0.3746 - val_accuracy: 0.8127\n",
      "Epoch 60/75\n",
      "441/441 [==============================] - 66s 151ms/step - loss: 0.4064 - accuracy: 0.8253 - val_loss: 0.3534 - val_accuracy: 0.8522\n",
      "Epoch 61/75\n",
      "441/441 [==============================] - 67s 151ms/step - loss: 0.4040 - accuracy: 0.8248 - val_loss: 0.3208 - val_accuracy: 0.8671\n",
      "Epoch 62/75\n",
      "441/441 [==============================] - 67s 151ms/step - loss: 0.4031 - accuracy: 0.8212 - val_loss: 0.3194 - val_accuracy: 0.8661\n",
      "Epoch 63/75\n",
      "441/441 [==============================] - 67s 151ms/step - loss: 0.4018 - accuracy: 0.8251 - val_loss: 0.3378 - val_accuracy: 0.8500\n",
      "Epoch 64/75\n",
      "441/441 [==============================] - 66s 151ms/step - loss: 0.4043 - accuracy: 0.8249 - val_loss: 0.3754 - val_accuracy: 0.8177\n",
      "Epoch 65/75\n",
      "441/441 [==============================] - 67s 151ms/step - loss: 0.4025 - accuracy: 0.8246 - val_loss: 0.3285 - val_accuracy: 0.8592\n",
      "Epoch 66/75\n",
      "441/441 [==============================] - 66s 150ms/step - loss: 0.4051 - accuracy: 0.8247 - val_loss: 0.3260 - val_accuracy: 0.8364\n",
      "Epoch 67/75\n",
      "441/441 [==============================] - 69s 156ms/step - loss: 0.4023 - accuracy: 0.8211 - val_loss: 0.3263 - val_accuracy: 0.8639\n",
      "Epoch 68/75\n",
      "441/441 [==============================] - 69s 156ms/step - loss: 0.4005 - accuracy: 0.8262 - val_loss: 0.3274 - val_accuracy: 0.8639\n",
      "Epoch 69/75\n",
      "441/441 [==============================] - 70s 158ms/step - loss: 0.4057 - accuracy: 0.8241 - val_loss: 0.3520 - val_accuracy: 0.8291\n",
      "Epoch 70/75\n",
      "441/441 [==============================] - 69s 157ms/step - loss: 0.4020 - accuracy: 0.8241 - val_loss: 0.3264 - val_accuracy: 0.8658\n",
      "Epoch 71/75\n",
      "441/441 [==============================] - 69s 156ms/step - loss: 0.3980 - accuracy: 0.8241 - val_loss: 0.3454 - val_accuracy: 0.8310\n",
      "Epoch 72/75\n",
      "441/441 [==============================] - 69s 156ms/step - loss: 0.3958 - accuracy: 0.8272 - val_loss: 0.3319 - val_accuracy: 0.8652\n",
      "Epoch 73/75\n",
      "441/441 [==============================] - 67s 153ms/step - loss: 0.3961 - accuracy: 0.8275 - val_loss: 0.3242 - val_accuracy: 0.8639\n",
      "Epoch 74/75\n",
      "441/441 [==============================] - 67s 153ms/step - loss: 0.4011 - accuracy: 0.8239 - val_loss: 0.3404 - val_accuracy: 0.8304\n",
      "Epoch 75/75\n",
      "441/441 [==============================] - 70s 158ms/step - loss: 0.4023 - accuracy: 0.8214 - val_loss: 0.3368 - val_accuracy: 0.8297\n"
     ]
    }
   ],
   "source": [
    "#0ptimisation - Need to understand how the validation accuracy is compared here for feature extraction\n",
    "#from keras.optimizers import Adam, Adadelta, RMSprop\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "datagen.fit(train_image)\n",
    "\n",
    "# training\n",
    "history = model.fit_generator(datagen.flow(train_image,train_label, batch_size=32),\n",
    "                              epochs = 75,#epoch,batch_size can try with different values 50,100,\n",
    "                              shuffle=True,\n",
    "                              validation_data = (val_image,val_label),\n",
    "                              verbose = 1,\n",
    "                              steps_per_epoch=train_image.shape[0] // 32) #ned to change as per above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f83f86a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442/442 [==============================] - 11s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14123, 256)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Extract the train - intermediate output from CNN\n",
    "intermediate_output = intermediate_layer_model.predict(train_image) \n",
    "intermediate_output = pd.DataFrame(data=intermediate_output)\n",
    "intermediate_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9bde5307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3160, 28, 28, 1)\n",
      "(3160, 10)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of test dataset\n",
    "print(val_image.shape)\n",
    "print(val_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d47c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the dataset for XGBoost model building\n",
    "val_data = intermediate_output[10963:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "acd70a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 3s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "# Extract the test - intermediate output from CNN\n",
    "intermediate_test_output = intermediate_layer_model.predict(test_image)\n",
    "intermediate_test_output = pd.DataFrame(data=intermediate_test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b37b85",
   "metadata": {},
   "source": [
    "#### <font color='blue'> 14. XGBooost model creation for intermediate values </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "849eefbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14123, 256)\n",
      "(14123,)\n",
      "(14123, 256)\n",
      "(3160,)\n"
     ]
    }
   ],
   "source": [
    "#printing shape of intermediate values\n",
    "print(intermediate_output.shape)\n",
    "print(train_label1.shape)\n",
    "print(val_data.shape)\n",
    "print(val_label1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "030ccfde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10963"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14123 - 3160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d8358af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.94%\n"
     ]
    }
   ],
   "source": [
    "# #XGBoost model creation & XGBoost evaluate predictions\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(intermediate_output, train_label1)\n",
    "# make predictions for test data\n",
    "y_pred = xgb_model.predict(val_data)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(val_label1, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7975479f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36dc82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_xgb = xgb_model.predict(intermediate_test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53a1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5eae65ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = list()\n",
    "resample = list()\n",
    "precision = list()\n",
    "recall = list()\n",
    "F1score = list()\n",
    "AUCROC = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "491cf7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval( y_test, y_pred, algo=None, sampling=None):\n",
    "    # Test set prediction\n",
    "    #y_prob=clf_model.predict_proba(X_test)\n",
    "    #y_pred=clf_model.predict(X_test)\n",
    "    \n",
    "    #print('Confusion Matrix')\n",
    "    print('='*60)\n",
    "    print('Classification Report')\n",
    "    print('='*60)\n",
    "    print(classification_report(y_test,y_pred),\"\\n\")\n",
    "    #print('AUC-ROC')\n",
    "    #print('='*60)\n",
    "    #print(roc_auc_score(y_test, y_prob[:,1]))\n",
    "          \n",
    "    #model.append(algo)\n",
    "    precision.append(precision_score(y_test,y_pred))\n",
    "    recall.append(recall_score(y_test,y_pred))\n",
    "    F1score.append(f1_score(y_test,y_pred))\n",
    "    #AUCROC.append(roc_auc_score(y_test, y_prob[:,1]))\n",
    "    #resample.append(sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13dec3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.95      0.91      2793\n",
      "         1.0       0.73      0.50      0.59       767\n",
      "\n",
      "    accuracy                           0.85      3560\n",
      "   macro avg       0.80      0.72      0.75      3560\n",
      "weighted avg       0.84      0.85      0.84      3560\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_eval(test_label, submission_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9f95304b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2654  139]\n",
      " [ 387  380]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    " print(confusion_matrix(test_label,submission_xgb),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa484a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                confusion_matrix(test_label,submission_xgb).flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     confusion_matrix(test_label,submission_xgb).flatten()/np.sum(confusion_matrix(test_label,submission_xgb))]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(confusion_matrix(test_label,submission_xgb),fmt='', cmap='Blues', annot=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca93c3",
   "metadata": {},
   "source": [
    "https://github.com/arpcode/SMOTE-ADA-BOOST-COBRA/blob/main/Notebooks/SmoteAdaBoostedCC.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc418531",
   "metadata": {},
   "source": [
    "#### K-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec15c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68772682",
   "metadata": {},
   "source": [
    "#### Train Acuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de409efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.14%\n"
     ]
    }
   ],
   "source": [
    "#Train Acuracy\n",
    "# k-fold cross validation evaluation of xgboost model\n",
    "from numpy import loadtxt\n",
    "import xgboost\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "results = cross_val_score(xgb_model, intermediate_output, train_label1, cv=kfold)\n",
    "print(\"Accuracy: %.2f%%\" % (results.mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ae8a18",
   "metadata": {},
   "source": [
    "#### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4964bc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.36%\n"
     ]
    }
   ],
   "source": [
    "#Test Accuracy\n",
    "kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "test_results = cross_val_score(xgb_model, intermediate_test_output, test_label, cv=kfold)\n",
    "#Test_results = cross_val_score(xgb_model, intermediate_output, val_label1, cv=kfold)\n",
    "#cv_results = cross_validate(xgb_model, X, y, cv=kfold, scoring=accuracy, verbose=10)\n",
    "print(\"Accuracy: %.2f%%\" % (test_results.mean()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b32536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
